\chapter{Image Inpainting}

\section{Présentation du problème}

L'inpainting désigne la reconstruction d'images détériorées. Le cas le plus souvent étudié est celui de parties manquantes de l'image comme obtenu au chapitre précédent qu'il va falloir remplir de la manière la plus plausible possible.
Ce problème trouve plusieurs applications concrètes : la restauration d'oeuvres d'arts anciennes, la retouche d'images pour retirer des objets dans le décor sont les plus évidentes, mais on peut également l'utiliser afin d'augmenter la résolution d'une image. En effet, en dilatant l'image et en laissant des trous entre les pixels, le remplissage desdits trous revient à de l'inpainting.

\begin{figure}[!h]
    \centering
    \includegraphics[width= 400pt,valign=t]{"images/Image_inpainting/resolution"}
    \caption{Exemple du procédé de dilatation pour augmente r la résolution. Ici réalisé par les chercheurs de Nvidia \cite{liu_image_2018}}
\end{figure}

Plusieurs techniques ont été développées pour travailler sur ce problème dont certaines non apprenantes comme PatchMatch. Nous étudierons ici deux aspects marquants de l'architecture développée par Nvidia qui pourraient être réutilisés dans d'autres projets.\\
\section{Partial Convolution Inpainting}
L'architecture développée est de type U-net. L'idée est par des convolutions partielles successives d'obtenir une sortie intermédiaire sans trous avant de remonter par des couches de NearestUpSample à une image de la bonne taille. La structure détaillée se trouve dans l'appendix du papier. \cite{liu_image_2018}
\subsection{Convolution partielle}
L'idée principale du papier est donc cette convolution partielle. 
On considère les pixels \textbf{X} et un masque \textbf{M} binaire de même taille que \textbf{X} tel que $M_{ij} = 0$ si le pixel est à compléter et $M_{ij} = 1$ sinon. Soit $\textbf{1}$ la matrice composée uniquement de 1 et de la même taille que M. Soit enfin $\odot$ la multiplication terme à terme.
La formule donnant la sortie $y$ de la convolution partielle est alors :
\begin{equation}
    y = \left\{ \begin{array}{ll}
        \textbf{W}^T (\textbf{X} \odot \textbf{M} ) \frac{\sum_{ij} 1_{ij}}{\sum_{ij} M_{ij}}+ b & \mbox{ si} \sum_{ij} M_{ij} > 0 \\
        0 & \mbox{ si} \sum_{ij} M_{ij} = 0
        \end{array}
        \right.
\end{equation}
Ainsi la convolution n'a lieu que sur les pixels où on peut obtenir une valeur grâce à l'apport d'information des pixels alentours. On évite donc les dérives liées au biais. On remplace donc cela dans la traditionnelle couche de convolution et on fait se déplacer le centre. Cette formule permet alors de réduire le masque. En effet, le masque vaudra pour la prochaine étape de convolution 0 si et seulement si on a y=0.\\
Dans le cas d'une vraie image, seul le coeur du masque peut se retrouver suffisamment éloigné de tout pixel porteur d'information pour que la convolution renvoie 0. On peut donc progressivement en appliquant plusieurs étapes de convolution partielle arriver à des features sans trou. On peut donc remplir l'image et ce quelle que soit la forme du trou ! Cependant on peut se rendre compte dès maintenant que l'on va voir plus de mal à approximer quelques trous larges que beaucoup de trous fins comme dans l'amélioration de la résolution.

\begin{figure}[!h]
    \centering
    \includegraphics{"images/Image_inpainting/val0masque"}
    \caption{Dans cet exemple de masque seul le cas en violet mènera à une valeur de 0 dans le futur masque.}
\end{figure}


\subsection{Fonction de coût}
La fonction de coût est composé de quatre parties.
\subsubsection{Coût par pixel}
Il s'agit d'une fonction qui mesure l'écart pixel à pixel. Une simple norme L1 qui assure que l'image ne diffère pas trop de l'original. Il s'agit de la fonction la plus intuitive. Si I est l'image, $L_{pixel} = ||I_{vrai} - {I_out}||_1$
\subsubsection{Variation totale}
Une fonction classique en traitement du signal qui vérifie que les écarts de valeurs ne sont pas trop brusques entre 2 pixels. Cela tend donc à "lisser" l'image.
\subsubsection{VGG16}
Le point intéressant de la fonction de coût est l'utilisation d'un deuxième réseau préentrainé. Un VGG16 est un CNN pré-entrainé sur le dataset ImageNet qui permet d'identifier des features dans une image afin de déterminer ce qu'elle contient. L'idée est donc tout d'abord d'appliquer une loss pixel à pixel mais dans les espaces de features que VGG16 produit (sur une ou plusieurs couches). On passe donc l'image originale et celle reconstruite dans le VGG16, et on calcule la loss sur les espaces de features. Ainsi, si les deux images sont proches, on devrait obtenir les même features dans l'image et conserver des yeux par exemple. \\
Une deuxième utilisation est faite des features de VGG16. On calcule la matrice de Gram des features produites par le VGG16. On obtient ainsi le "style" de l'image, c'est à dire son ton et sa texture. On applique ensuite une loss L1.

\section{Conclusion}
Cette section se voulait être une introduction au problème d'image inpainting et présenter dans les grandes lignes les spécificités réapplicables d'une architecture traitant ce sujet. Nous ne rentrons pas dans les détails, car le temps de calcul que demande cette méthode est assez élevé (72h environ) et cette architecture n'est pas l'objectif du projet, l'implémentation n'a pas été réalisé par nos soins. Il s'agissait donc de survoler la technologie et son fonctionnement. Maintenant que nous avons cerné le sujet et un point de comparaison pour notre cycleGAN, voyons comment nous pouvons l'adapter au problème.

